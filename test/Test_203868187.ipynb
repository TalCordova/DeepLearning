{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import transformers\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dropout\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Load Data Labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "##label dictionary\n",
    "f = open('atis/intent_label.txt', 'r', encoding=\"utf8\") # opening a file\n",
    "labels = f.readlines()\n",
    "labels = [str(i)[:-1] for i in labels]\n",
    "num_labels = len(labels)\n",
    "labels = dict(zip(labels, range(0, 22)))\n",
    "\n",
    "# load train text\n",
    "f = open('atis/train/seq.in')\n",
    "content = f.readlines()\n",
    "train_text = [str(x)[:-1] for x in content]\n",
    "f = open('atis/train/label')\n",
    "content = f.readlines()\n",
    "train_labels = [str(x)[:-1] for x in content]\n",
    "train_labels = [labels.get(label, 0) for label in train_labels]\n",
    "\n",
    "# load dev text\n",
    "f = open('atis/dev/seq.in')\n",
    "content = f.readlines()\n",
    "dev_text = [str(x)[:-1] for x in content]\n",
    "f = open('atis/dev/label')\n",
    "content = f.readlines()\n",
    "dev_labels = [str(x)[:-1] for x in content]\n",
    "dev_labels = [labels.get(label, 0) for label in dev_labels]\n",
    "\n",
    "# load test text\n",
    "f = open('atis/test/seq.in')\n",
    "content = f.readlines()\n",
    "test_text = [str(x)[:-1] for x in content]\n",
    "f = open('atis/test/label')\n",
    "content = f.readlines()\n",
    "test_labels = [str(x)[:-1] for x in content]\n",
    "test_labels = [labels.get(label, 0) for label in test_labels]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-A: Intent Classification with LSTM\n",
    "\n",
    "#### Pre-Processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "num_words = 1000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token)\n",
    "tokenizer.fit_on_texts(train_text)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "train_sequences = tokenizer.texts_to_sequences(train_text)\n",
    "\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "train_padded = np.array(train_padded)\n",
    "\n",
    "val_sequence = tokenizer.texts_to_sequences(dev_text)\n",
    "val_padded = pad_sequences(val_sequence, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "val_padded = np.array(val_padded)\n",
    "\n",
    "test_sequence = tokenizer.texts_to_sequences(test_text)\n",
    "test_padded = pad_sequences(test_sequence, padding=pad_type, truncating=trunc_type, maxlen=maxlen)\n",
    "test_padded = np.array(test_padded)\n",
    "\n",
    "train_labels = np.array(train_labels)\n",
    "dev_labels = np.array(dev_labels)\n",
    "test_labels = np.array(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "max_sentence_length = maxlen\n",
    "embedding_vector_length = len(train_padded)\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_length=max_sentence_length, output_dim=num_labels, input_dim=embedding_vector_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(num_labels))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 64\n",
    "model.fit(train_padded, train_labels.reshape(-1,1), validation_data=(val_padded, dev_labels.reshape(-1,1)), epochs=num_epochs, batch_size=batch_size, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 46, 22)            98516     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 46, 22)            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 22)                3960      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 22)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 23        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102,499\n",
      "Trainable params: 102,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "70/70 [==============================] - 2s 16ms/step - loss: -21.3174 - accuracy: 0.0290 - val_loss: -48.3426 - val_accuracy: 0.0340\n",
      "Epoch 2/3\n",
      "70/70 [==============================] - 1s 14ms/step - loss: -64.7194 - accuracy: 0.0290 - val_loss: -79.4997 - val_accuracy: 0.0340\n",
      "Epoch 3/3\n",
      "70/70 [==============================] - 1s 15ms/step - loss: -90.5668 - accuracy: 0.0290 - val_loss: -101.1044 - val_accuracy: 0.0340\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1dbae955070>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate LSTM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 7ms/step - loss: -99.4407 - accuracy: 0.0370\n",
      "Accuracy: 3.70%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_padded, test_labels.reshape(-1, 1), verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-B: Inent Classification with BERT\n",
    "\n",
    "#### Functions and Classes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text, text_labels):\n",
    "\n",
    "        self.labels = text_labels\n",
    "        self.texts = [tokenizer(t, padding='max_length',max_length=maxlen,  truncation=True, return_tensors=\"pt\") for t in text]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        # return torch.Tensor(self.labels[idx])\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y\n",
    "\n",
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.bert = self.bert\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, num_labels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer\n",
    "\n",
    "\n",
    "def train(model, train_data, train_labels, val_data, val_labels, learning_rate, epochs):\n",
    "    train, val = Dataset(train_data, train_labels), Dataset(val_data, val_labels)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            train_labelTensor = train_label.type(torch.LongTensor).to(device)\n",
    "            batch_loss = criterion(output, train_labelTensor)\n",
    "            total_loss_train += batch_loss.item()\n",
    "\n",
    "            acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            model.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for val_input, val_label in val_dataloader:\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "\n",
    "                val_labelTensor = val_label.type(torch.LongTensor).to(device)\n",
    "                batch_loss = criterion(output, val_labelTensor)\n",
    "                total_loss_val += batch_loss.item()\n",
    "\n",
    "                acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "\n",
    "        print(\n",
    "            f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n",
    "                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "\n",
    "\n",
    "def evaluate(model, test_data, test_labels):\n",
    "    test = Dataset(test_data, test_labels)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    print(f'Model Predictions: {output.argmax(dim=1)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train BERT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 11.00 GiB total capacity; 418.80 MiB already allocated; 0 bytes free; 472.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_11816/2619671480.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mBertClassifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mLR\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1e-6\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_text\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdev_text\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdev_labels\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mLR\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mEPOCHS\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_11816/2141535479.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(model, train_data, train_labels, val_data, val_labels, learning_rate, epochs)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0muse_cuda\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m         \u001B[0mcriterion\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcriterion\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36mcuda\u001B[1;34m(self, device)\u001B[0m\n\u001B[0;32m    678\u001B[0m             \u001B[0mModule\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    679\u001B[0m         \"\"\"\n\u001B[1;32m--> 680\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    681\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    682\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mxpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mUnion\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    568\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    569\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mchildren\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 570\u001B[1;33m             \u001B[0mmodule\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfn\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    571\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    572\u001B[0m         \u001B[1;32mdef\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtensor_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    591\u001B[0m             \u001B[1;31m# `with torch.no_grad():`\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    592\u001B[0m             \u001B[1;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 593\u001B[1;33m                 \u001B[0mparam_applied\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    594\u001B[0m             \u001B[0mshould_use_set_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompute_should_use_set_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mparam\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mparam_applied\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    595\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mshould_use_set_data\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m    678\u001B[0m             \u001B[0mModule\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    679\u001B[0m         \"\"\"\n\u001B[1;32m--> 680\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_apply\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    681\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    682\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mxpu\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mUnion\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mint\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 11.00 GiB total capacity; 418.80 MiB already allocated; 0 bytes free; 472.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "train(model, train_text, train_labels, dev_text, dev_labels, LR, EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluate BERT"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate(model, test_data, test_labels):\n",
    "    test = Dataset(test_data, test_labels)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "    device = \"cpu\"\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "\n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    print(f'Model Predictions: {output.argmax(dim=1)}')\n",
    "evaluate(model, test_text, test_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}